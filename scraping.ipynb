{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777afeb6",
   "metadata": {},
   "source": [
    "## This file will focus strictly on scraping data from the website fbref.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c505bcaf-a286-4bff-9a2f-42650bafdad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\tom\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\tom\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\tom\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.18.0)\n",
      "Requirement already satisfied: python-Levenshtein in c:\\users\\tom\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.25.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 2)) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: Levenshtein==0.25.1 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from python-Levenshtein->-r requirements.txt (line 5)) (0.25.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from Levenshtein==0.25.1->python-Levenshtein->-r requirements.txt (line 5)) (3.9.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tom\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c64d049-ea7f-4be3-b8e0-02ec7829e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d06bf7b",
   "metadata": {},
   "source": [
    "### Defining functions\n",
    "\n",
    "\n",
    "`get_data_from_txt()` takes a file path, reads the HTML content, and returns a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74caa9be-6fb2-4199-a18b-44b7a9dcdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_txt(file_path):\n",
    "    # Read the HTML content from the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the table\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    if not table:\n",
    "        raise ValueError(\"No table found in the HTML content\")\n",
    "    \n",
    "    # Extract column names from thead\n",
    "    thead = table.find('thead')\n",
    "    if thead:\n",
    "        column_headers = thead.find_all('th')\n",
    "        column_names = [th.get('aria-label', th.text.strip()) for th in column_headers]\n",
    "    else:\n",
    "        column_names = []\n",
    "    \n",
    "    # Extract data from tbody\n",
    "    tbody = table.find('tbody')\n",
    "    data = []\n",
    "    if tbody:\n",
    "        for row in tbody.find_all('tr'):\n",
    "            row_data = [cell.text.strip() for cell in row.find_all(['th', 'td'])]\n",
    "            data.append(row_data)\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Assign column names, truncating or padding as necessary\n",
    "    if len(df.columns) > len(column_names):\n",
    "        # If there are more columns in the data than names, use the first len(column_names) columns\n",
    "        df = df.iloc[:, :len(column_names)]\n",
    "    elif len(df.columns) < len(column_names):\n",
    "        # If there are fewer columns in the data than names, truncate the column names\n",
    "        column_names = column_names[:len(df.columns)]\n",
    "    \n",
    "    df.columns = column_names\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d08eda",
   "metadata": {},
   "source": [
    "### Getting Team data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafbf928",
   "metadata": {},
   "source": [
    "`get_squad_stats()` scrapes fbref link html for standard squad stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f825cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squad_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/stats/squads/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_teams_standard_for')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/squad_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved squad stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "            \n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/squad_stats_{season}.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743528c",
   "metadata": {},
   "source": [
    "`get_squad_wages()` scrapes fbref link html for squad wages, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48ae2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squad_wages():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/wages/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_squad_wages')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/squad_wages_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved squad wages for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/squad_wages_{season}.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2325a6",
   "metadata": {},
   "source": [
    "### Getting Player data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a1a6b",
   "metadata": {},
   "source": [
    "`get_standard_stats()` scrapes fbref link html for defensive stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d18b414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/stats/players/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "            #url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "        #else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_standard')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/standard_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved standard stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/standard_stats_{season}.txt'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516e41e",
   "metadata": {},
   "source": [
    "`get_defensive_stats()` scrapes fbref link html for defensive stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "238f043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_defensive_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/defense/players/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_defense')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/defensive_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved defensive stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/defensive_stats_{season}.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81790d",
   "metadata": {},
   "source": [
    "`get_passing_stats()` scrapes fbref link html for defensive stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6632504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_passing_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/passing/players/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_passing')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/passing_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved passing stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/passing_stats_{season}.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b697c52",
   "metadata": {},
   "source": [
    "`get_goalkeeping_stats()` scrapes fbref link html for goalkeeper stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96ad3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goalkeeping_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/keepers/players/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_keeper')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/goalkeeping_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved goalkeeping stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/goalkeeping_stats_{season}.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a0231",
   "metadata": {},
   "source": [
    "### Get all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943f121",
   "metadata": {},
   "source": [
    "`get_all_seasons()` loops through all the txt files, extracts the data, and adds it to a dataframe for all seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eda85a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_seasons():\n",
    "    # List of seasons to loop through\n",
    "    seasons = ['2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
    "    # dataframes to store squad stats, and wages\n",
    "    seasons_squads_stats = []\n",
    "    seasons_squads_wages = []\n",
    "    seasons_standard_stats = []\n",
    "    seasons_defensive_stats = []\n",
    "    seasons_passing_stats = []\n",
    "    seasons_goalkeeping_stats = []\n",
    "    \n",
    "    # Getting squads stats data\n",
    "    get_squad_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/squad_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        seasons_squads_stats.append(df)\n",
    "        \n",
    "    # Getting squad wages data\n",
    "    get_squad_wages()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/squad_wages_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        seasons_squads_wages.append(df)\n",
    "    \n",
    "    # Getting standard player stats\n",
    "    get_standard_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/standard_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        seasons_standard_stats.append(df)\n",
    "        \n",
    "    # Getting defensive player stats\n",
    "    get_defensive_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/defensive_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        seasons_defensive_stats.append(df)\n",
    "    \n",
    "    # Getting passing player stats\n",
    "    get_passing_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/passing_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        seasons_passing_stats.append(df)\n",
    "        \n",
    "    # Getting goalkeeping player stats\n",
    "    get_goalkeeping_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/goalkeeping_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        seasons_goalkeeping_stats.append(df)\n",
    "    \n",
    "    \n",
    "    squads_stats = pd.concat(seasons_squads_stats, ignore_index=True)\n",
    "    squads_wages = pd.concat(seasons_squads_wages, ignore_index=True)\n",
    "    standard_stats = pd.concat(seasons_standard_stats, ignore_index=True)\n",
    "    defensive_stats = pd.concat(seasons_defensive_stats, ignore_index=True)\n",
    "    passing_stats = pd.concat(seasons_passing_stats, ignore_index=True)\n",
    "    goalkeeping_stats = pd.concat(seasons_goalkeeping_stats, ignore_index=True)\n",
    "    \n",
    "    return squads_stats, squads_wages, standard_stats, defensive_stats, passing_stats, goalkeeping_stats\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "834c7d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\Tom\\AppData\\Local\\Temp\\ipykernel_2096\\520910664.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  stats_output_path = 'uncleaned_data_csv\\seasons_stats.csv'\n",
      "C:\\Users\\Tom\\AppData\\Local\\Temp\\ipykernel_2096\\520910664.py:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  wages_output_path = 'uncleaned_data_csv\\seasons_wages.csv'\n",
      "C:\\Users\\Tom\\AppData\\Local\\Temp\\ipykernel_2096\\520910664.py:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  standard_output_path = 'uncleaned_data_csv\\standard.csv'\n",
      "C:\\Users\\Tom\\AppData\\Local\\Temp\\ipykernel_2096\\520910664.py:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  defending_output_path = 'uncleaned_data_csv\\defending.csv'\n",
      "C:\\Users\\Tom\\AppData\\Local\\Temp\\ipykernel_2096\\520910664.py:10: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  passing_output_path = 'uncleaned_data_csv\\passing.csv'\n",
      "C:\\Users\\Tom\\AppData\\Local\\Temp\\ipykernel_2096\\520910664.py:11: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  goalkeeping_output_path = 'uncleaned_data_csv\\goalkeeping.csv'\n"
     ]
    }
   ],
   "source": [
    "def scrape_all_data():\n",
    "    # get squads stats, squad wages, standard player stats, defensive stats, passing stats, and goalkeeping for all seasons\n",
    "    squads_stats, squads_wages, standard_stats, defensive_stats, passing_stats, goalkeeping_stats = get_all_seasons()\n",
    "\n",
    "    # output paths\n",
    "    stats_output_path = 'uncleaned_data_csv\\seasons_stats.csv'\n",
    "    wages_output_path = 'uncleaned_data_csv\\seasons_wages.csv'\n",
    "    standard_output_path = 'uncleaned_data_csv\\standard.csv'\n",
    "    defending_output_path = 'uncleaned_data_csv\\defending.csv'\n",
    "    passing_output_path = 'uncleaned_data_csv\\passing.csv'\n",
    "    goalkeeping_output_path = 'uncleaned_data_csv\\goalkeeping.csv'\n",
    "    \n",
    "    # To csv\n",
    "    squads_stats.to_csv(stats_output_path, index=False)\n",
    "    squads_wages.to_csv(wages_output_path, index=False)\n",
    "    standard_stats.to_csv(standard_output_path, index=False)\n",
    "    defensive_stats.to_csv(defending_output_path, index=False)\n",
    "    passing_stats.to_csv(passing_output_path, index=False)\n",
    "    goalkeeping_stats.to_csv(goalkeeping_output_path, index=False)\n",
    "    \n",
    "    # print them out\n",
    "    print(squads_stats.head())\n",
    "    print(squads_wages.head())\n",
    "    print(standard_stats.head())\n",
    "    print(defensive_stats.head())\n",
    "    print(passing_stats.head())\n",
    "    print(goalkeeping_stats.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b68f20d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved squad stats for 2017-2018\n",
      "Saved squad stats for 2018-2019\n",
      "Saved squad stats for 2019-2020\n",
      "Saved squad stats for 2020-2021\n",
      "Saved squad stats for 2021-2022\n",
      "Saved squad stats for 2022-2023\n",
      "Saved squad stats for 2023-2024\n",
      "All seasons processed\n",
      "Saved squad wages for 2017-2018\n",
      "Saved squad wages for 2018-2019\n",
      "Saved squad wages for 2019-2020\n",
      "Saved squad wages for 2020-2021\n",
      "Saved squad wages for 2021-2022\n",
      "Saved squad wages for 2022-2023\n",
      "Saved squad wages for 2023-2024\n",
      "All seasons processed\n",
      "Saved standard stats for 2017-2018\n",
      "Saved standard stats for 2018-2019\n",
      "Saved standard stats for 2019-2020\n",
      "Saved standard stats for 2020-2021\n",
      "Saved standard stats for 2021-2022\n",
      "Saved standard stats for 2022-2023\n",
      "Saved standard stats for 2023-2024\n",
      "All seasons processed\n",
      "Saved defensive stats for 2017-2018\n",
      "Saved defensive stats for 2018-2019\n",
      "Saved defensive stats for 2019-2020\n",
      "Saved defensive stats for 2020-2021\n",
      "Saved defensive stats for 2021-2022\n",
      "Saved defensive stats for 2022-2023\n",
      "Saved defensive stats for 2023-2024\n",
      "All seasons processed\n",
      "Saved passing stats for 2017-2018\n",
      "Saved passing stats for 2018-2019\n",
      "Saved passing stats for 2019-2020\n",
      "Saved passing stats for 2020-2021\n",
      "Saved passing stats for 2021-2022\n",
      "Saved passing stats for 2022-2023\n",
      "Saved passing stats for 2023-2024\n",
      "All seasons processed\n",
      "Saved goalkeeping stats for 2017-2018\n",
      "Saved goalkeeping stats for 2018-2019\n",
      "Saved goalkeeping stats for 2019-2020\n",
      "Saved goalkeeping stats for 2020-2021\n",
      "Saved goalkeeping stats for 2021-2022\n",
      "Saved goalkeeping stats for 2022-2023\n",
      "Saved goalkeeping stats for 2023-2024\n",
      "All seasons processed\n",
      "                                                    Rk Squad Competition  \\\n",
      "0  1    Alavés          es La Liga  30  25.5  40.3  38   418       3,420   \n",
      "1  2    Amiens          fr Ligue 1  30  27.5  43.3  38   418       3,420   \n",
      "2  3    Angers          fr Ligue 1  27  27.1  45.1  38   418       3,420   \n",
      "3  4   Arsenal  eng Premier League  30  26.8  61.4  38   418       3,420   \n",
      "4  5  Atalanta          it Serie A  25  25.7  55.4  38   418       3,420   \n",
      "\n",
      "  # of Players  ... xG: Expected Goals npxG: Non-Penalty xG  \\\n",
      "0         38.0  ...               1.05                 0.82   \n",
      "1         38.0  ...               0.95                 0.63   \n",
      "2         38.0  ...               1.08                 0.79   \n",
      "3         38.0  ...               1.92                 1.61   \n",
      "4         38.0  ...               1.50                 1.00   \n",
      "\n",
      "  xAG: Exp. Assisted Goals npxG + xAG Progressive Carries Progressive Passes  \\\n",
      "0                     1.87       1.03                1.84               1.01   \n",
      "1                     1.58       0.87                1.50               0.86   \n",
      "2                     1.87       0.97                1.76               1.25   \n",
      "3                     3.53       1.82                3.42               1.80   \n",
      "4                     2.50       1.37                2.37               1.69   \n",
      "\n",
      "  Goals/90 Assists/90 Goals + Assists/90 Non-Penalty Goals/90  \n",
      "0     0.73       1.74               0.95                 1.68  \n",
      "1     0.56       1.42               0.78                 1.35  \n",
      "2     0.93       2.18               1.17                 2.10  \n",
      "3     1.40       3.20               1.69                 3.10  \n",
      "4     1.18       2.86               1.50                 2.68  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "  Rk           Squad         Competition # of Players  \\\n",
      "0  1       Barcelona          es La Liga           33   \n",
      "1  2     Real Madrid          es La Liga           33   \n",
      "2  3       Paris S-G          fr Ligue 1           35   \n",
      "3  4  Manchester Utd  eng Premier League           35   \n",
      "4  5         Arsenal  eng Premier League           45   \n",
      "\n",
      "                            Weekly Wages  \\\n",
      "0  € 4,682,115 (£ 3,925,993, $4,771,599)   \n",
      "1  € 3,949,904 (£ 3,312,027, $4,025,393)   \n",
      "2  € 3,895,462 (£ 3,266,377, $3,969,910)   \n",
      "3  € 3,810,955 (£ 3,195,596, $3,883,356)   \n",
      "4  € 3,629,433 (£ 3,043,385, $3,698,385)   \n",
      "\n",
      "                                  Annual Wages % Estimated  \n",
      "0  € 243,470,000 (£ 204,151,634, $248,123,125)        100%  \n",
      "1  € 205,395,000 (£ 172,225,426, $209,320,446)        100%  \n",
      "2  € 202,564,000 (£ 169,851,608, $206,435,344)        100%  \n",
      "3  € 198,169,670 (£ 166,171,000, $201,934,520)        100%  \n",
      "4  € 188,730,521 (£ 158,256,000, $192,316,043)        100%  \n",
      "                                                                               \\\n",
      "0  1  Patrick van Aanholt   nl NED     DF  Crystal Palace  eng Premier League   \n",
      "1  2       Rolando Aarons  eng ENG  MF,FW   Newcastle Utd  eng Premier League   \n",
      "2  3       Rolando Aarons  eng ENG  MF,FW   Hellas Verona          it Serie A   \n",
      "3  4        Ignazio Abate   it ITA     DF           Milan          it Serie A   \n",
      "4  5      Aymen Abdennour   tn TUN     DF       Marseille          fr Ligue 1   \n",
      "\n",
      "         Rk Player Nation  ... npxG: Non-Penalty xG xAG: Exp. Assisted Goals  \\\n",
      "0  26  1990     28     25  ...                 0.04                     0.25   \n",
      "1  21  1995      4      1  ...                 0.00                     0.00   \n",
      "2  21  1995     11      6  ...                 0.00                     0.00   \n",
      "3  30  1986     17     11  ...                 0.00                     0.09   \n",
      "4  27  1989      8      6  ...                 0.00                     0.00   \n",
      "\n",
      "  npxG + xAG Progressive Carries Progressive Passes Progressive Passes Rec  \\\n",
      "0       0.21                0.25               0.13                   0.09   \n",
      "1       0.00                0.00               0.04                   0.00   \n",
      "2       0.00                0.00               0.03                   0.03   \n",
      "3       0.09                0.09               0.01                   0.04   \n",
      "4       0.00                0.00               0.02                   0.00   \n",
      "\n",
      "  Goals/90 Assists/90 Goals + Assists/90 Non-Penalty Goals/90  \n",
      "0     0.21       0.13               0.21              Matches  \n",
      "1     0.04       0.04               0.04              Matches  \n",
      "2     0.06       0.03               0.06              Matches  \n",
      "3     0.06       0.01               0.06              Matches  \n",
      "4     0.02       0.02               0.02              Matches  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "                                                                               \\\n",
      "0  1  Patrick van Aanholt   nl NED     DF  Crystal Palace  eng Premier League   \n",
      "1  2       Rolando Aarons  eng ENG  MF,FW   Newcastle Utd  eng Premier League   \n",
      "2  3       Rolando Aarons  eng ENG  MF,FW   Hellas Verona          it Serie A   \n",
      "3  4        Ignazio Abate   it ITA     DF           Milan          it Serie A   \n",
      "4  5      Aymen Abdennour   tn TUN     DF       Marseille          fr Ligue 1   \n",
      "\n",
      "   Rk Player Nation Position  ... Tackles Won Tackles (Def 3rd)  \\\n",
      "0  26   1990   24.3       47  ...        47.1                18   \n",
      "1  21   1995    1.5        4  ...        66.7                 2   \n",
      "2  21   1995    5.7       13  ...        14.3                 6   \n",
      "3  30   1986   11.7       20  ...        54.5                 5   \n",
      "4  27   1989    5.5        7  ...        57.1                 3   \n",
      "\n",
      "  Tackles (Mid 3rd) Tackles (Att 3rd) Dribblers Tackled Dribbles Challenged  \\\n",
      "0                24                 5                19                  47   \n",
      "1                 3                 0                 3                   1   \n",
      "2                 3                 1                 2                   2   \n",
      "3                22                 2                20                   8   \n",
      "4                 5                 5                 0                   4   \n",
      "\n",
      "  % of Dribblers Tackled Challenges Lost Blocks Shots Blocked  \n",
      "0                     94              64      2       Matches  \n",
      "1                      5               0      0       Matches  \n",
      "2                     15               0      0       Matches  \n",
      "3                     28              29      0       Matches  \n",
      "4                     11              20      0       Matches  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "                                                                               \\\n",
      "0  1  Patrick van Aanholt   nl NED     DF  Crystal Palace  eng Premier League   \n",
      "1  2       Rolando Aarons  eng ENG  MF,FW   Newcastle Utd  eng Premier League   \n",
      "2  3       Rolando Aarons  eng ENG  MF,FW   Hellas Verona          it Serie A   \n",
      "3  4        Ignazio Abate   it ITA     DF           Milan          it Serie A   \n",
      "4  5      Aymen Abdennour   tn TUN     DF       Marseille          fr Ligue 1   \n",
      "\n",
      "                    Rk  ... Passes Completed (Short) Passes Attempted (Short)  \\\n",
      "0  26  1990  24.3  884  ...                        1                      2.1   \n",
      "1  21  1995   1.5   29  ...                        0                      0.0   \n",
      "2  21  1995   5.7   87  ...                        0                      0.2   \n",
      "3  30  1986  11.7  625  ...                        0                      0.5   \n",
      "4  27  1989   5.5  310  ...                        0                      0.0   \n",
      "\n",
      "  Pass Completion % (Short) Passes Completed (Medium)  \\\n",
      "0                       1.8                      -1.1   \n",
      "1                       0.0                       0.0   \n",
      "2                       0.1                      -0.2   \n",
      "3                       0.8                      -0.5   \n",
      "4                       0.0                       0.0   \n",
      "\n",
      "  Passes Attempted (Medium) Pass Completion % (Medium)  \\\n",
      "0                        18                         63   \n",
      "1                         0                          2   \n",
      "2                         3                          8   \n",
      "3                        10                         55   \n",
      "4                         0                          8   \n",
      "\n",
      "  Passes Completed (Long) Passes Attempted (Long) Pass Completion % (Long)  \\\n",
      "0                      28                       6                       92   \n",
      "1                       1                       1                        3   \n",
      "2                       7                       1                       17   \n",
      "3                      20                       7                       81   \n",
      "4                       0                       0                       12   \n",
      "\n",
      "   Assists  \n",
      "0  Matches  \n",
      "1  Matches  \n",
      "2  Matches  \n",
      "3  Matches  \n",
      "4  Matches  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "                                                                  Rk Player  \\\n",
      "0  1    Antonio Adán  es ESP  GK       Betis          es La Liga  30   1987   \n",
      "1  2      René Adler  de GER  GK    Mainz 05       de Bundesliga  32   1985   \n",
      "2  3          Adrián  es ESP  GK    West Ham  eng Premier League  30   1987   \n",
      "3  4         Alisson  br BRA  GK        Roma          it Serie A  24   1992   \n",
      "4  5  Sergio Álvarez  es ESP  GK  Celta Vigo          es La Liga  30   1986   \n",
      "\n",
      "  Nation Position  ... Goals Against Goals Against/90 Shots on Target Against  \\\n",
      "0     30       30  ...             4               12                       9   \n",
      "1     14       14  ...             3                6                       4   \n",
      "2     19       19  ...             6                6                       6   \n",
      "3     37       37  ...             8                7                      17   \n",
      "4     17       16  ...             6                7                       3   \n",
      "\n",
      "  Saves Save Percentage Wins Draws Losses Clean Sheets Clean Sheet Percentage  \n",
      "0  30.0               4    3     1      0         25.0                Matches  \n",
      "1  28.6               2    1     0      1          0.0                Matches  \n",
      "2  31.6               1    1     0      0          0.0                Matches  \n",
      "3  45.9               5    3     2      0         40.0                Matches  \n",
      "4  18.8               1    1     0      0          0.0                Matches  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "scrape_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc48ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
