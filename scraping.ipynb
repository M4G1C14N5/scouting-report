{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777afeb6",
   "metadata": {},
   "source": [
    "## This file will focus strictly on scraping data from the website fbref.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c505bcaf-a286-4bff-9a2f-42650bafdad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.18.0)\n",
      "Collecting python-Levenshtein (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for python-Levenshtein from https://files.pythonhosted.org/packages/2a/95/8c8fd923b0a702388da4f9e0368f490d123cc5224279e6a083984304a15e/python_levenshtein-0.27.1-py3-none-any.whl.metadata\n",
      "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 2)) (2.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\haiaj\\appdata\\roaming\\python\\python311\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\haiaj\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2023.3)\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for Levenshtein==0.27.1 from https://files.pythonhosted.org/packages/aa/ae/444d6e8ba9a35379a56926716f18bb2e77c6cf69e5324521fbe6885f14f6/levenshtein-0.27.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading levenshtein-0.27.1-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for rapidfuzz<4.0.0,>=3.9.0 from https://files.pythonhosted.org/packages/c9/5a/d00e1f63564050a20279015acb29ecaf41646adfacc6ce2e1e450f7f2633/rapidfuzz-3.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haiaj\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.16.0)\n",
      "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.27.1-cp311-cp311-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading rapidfuzz-3.13.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 52.2 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c64d049-ea7f-4be3-b8e0-02ec7829e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d06bf7b",
   "metadata": {},
   "source": [
    "### Defining functions\n",
    "\n",
    "\n",
    "`get_data_from_txt()` takes a file path, reads the HTML content, and returns a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74caa9be-6fb2-4199-a18b-44b7a9dcdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_txt(file_path):\n",
    "    # Read the HTML content from the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the table\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    if not table:\n",
    "        raise ValueError(\"No table found in the HTML content\")\n",
    "    \n",
    "    # Extract column names from thead\n",
    "    thead = table.find('thead')\n",
    "    if thead:\n",
    "        column_headers = thead.find_all('th')\n",
    "        column_names = [th.get('aria-label', th.text.strip()) for th in column_headers]\n",
    "    else:\n",
    "        column_names = []\n",
    "    \n",
    "    # Extract data from tbody\n",
    "    tbody = table.find('tbody')\n",
    "    data = []\n",
    "    if tbody:\n",
    "        for row in tbody.find_all('tr'):\n",
    "            row_data = [cell.text.strip() for cell in row.find_all(['th', 'td'])]\n",
    "            data.append(row_data)\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Assign column names, truncating or padding as necessary\n",
    "    if len(df.columns) > len(column_names):\n",
    "        # If there are more columns in the data than names, use the first len(column_names) columns\n",
    "        df = df.iloc[:, :len(column_names)]\n",
    "    elif len(df.columns) < len(column_names):\n",
    "        # If there are fewer columns in the data than names, truncate the column names\n",
    "        column_names = column_names[:len(df.columns)]\n",
    "    \n",
    "    df.columns = column_names\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d08eda",
   "metadata": {},
   "source": [
    "### Getting Team data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafbf928",
   "metadata": {},
   "source": [
    "`get_squad_stats()` scrapes fbref link html for standard squad stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f825cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squad_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "\n",
    "    # 🧢 Pretend to be a real Chrome browser\n",
    "    headers = {\n",
    "        'User-Agent': (\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "            'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "            'Chrome/124.0.0.0 Safari/537.36'\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/stats/squads/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2022-2023\"]  # 🧪 Start small to test\n",
    "\n",
    "    for season in seasons:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers=headers)\n",
    "            response.raise_for_status()  # Raise error for 403s or other HTTP issues\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table_div = soup.find('div', id='div_stats_teams_standard_for')\n",
    "            \n",
    "            if table_div:\n",
    "                with open(f'data_html/squad_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"✅ Saved squad stats for {season}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Table div not found for {season}\")\n",
    "            \n",
    "            time.sleep(random.uniform(5, 10))  # 💤 Nap time\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"❌ Failed to fetch data for season {season}: {e}\")\n",
    "            \n",
    "    print(\"✅ All seasons processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60713192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to fetch data for season 2022-2023: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2022-2023/stats/squads/2022-2023-Big-5-European-Leagues-Stats\n",
      "✅ All seasons processed\n"
     ]
    }
   ],
   "source": [
    "get_squad_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743528c",
   "metadata": {},
   "source": [
    "`get_squad_wages()` scrapes fbref link html for squad wages, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48ae2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squad_wages():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/wages/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_squad_wages')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/squad_wages_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved squad wages for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/squad_wages_{season}.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2325a6",
   "metadata": {},
   "source": [
    "### Getting Player data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a1a6b",
   "metadata": {},
   "source": [
    "`get_standard_stats()` scrapes fbref link html for defensive stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d18b414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/stats/players/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "            #url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "        #else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_standard')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/standard_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved standard stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/standard_stats_{season}.txt'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516e41e",
   "metadata": {},
   "source": [
    "`get_defensive_stats()` scrapes fbref link html for defensive stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238f043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_defensive_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/defense/players/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_defense')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/defensive_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved defensive stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/defensive_stats_{season}.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81790d",
   "metadata": {},
   "source": [
    "`get_passing_stats()` scrapes fbref link html for defensive stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6632504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_passing_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/passing/players/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_passing')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/passing_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved passing stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/passing_stats_{season}.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b697c52",
   "metadata": {},
   "source": [
    "`get_goalkeeping_stats()` scrapes fbref link html for goalkeeper stats, puts it in txt file, and returns txt file address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ad3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goalkeeping_stats():\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    base_url = \"https://fbref.com/en/comps/Big5/{}/keepers/players/{}-Big-5-European-Leagues-Stats\"\n",
    "    seasons = [\"2017-2018\", \"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "    \n",
    "    for season in seasons:\n",
    "        #if season == \"2023-2024\":\n",
    "           # url = \"https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\"\n",
    "       # else:\n",
    "        url = base_url.format(season, season)\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the div containing the table\n",
    "            table_div = soup.find('div', id='div_stats_keeper')\n",
    "            \n",
    "            if table_div:\n",
    "                # Save the HTML content of the div to a file\n",
    "                with open(f'data_html/goalkeeping_stats_{season}.txt', 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(table_div))\n",
    "                print(f\"Saved goalkeeping stats for {season}\")\n",
    "            else:\n",
    "                print(f\"Table div not found for {season}\")\n",
    "            \n",
    "            # Introduce a random delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch data for season {season}: {e}\")\n",
    "\n",
    "    print(\"All seasons processed\")\n",
    "    return f'data_html/goalkeeping_stats_{season}.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a0231",
   "metadata": {},
   "source": [
    "### Get all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943f121",
   "metadata": {},
   "source": [
    "`get_all_seasons()` loops through all the txt files, extracts the data, and adds it to a dataframe for all seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda85a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_seasons():\n",
    "    # List of seasons to loop through\n",
    "    seasons = ['2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
    "    # dataframes to store squad stats, and wages\n",
    "    seasons_squads_stats = []\n",
    "    seasons_squads_wages = []\n",
    "    seasons_standard_stats = []\n",
    "    seasons_defensive_stats = []\n",
    "    seasons_passing_stats = []\n",
    "    seasons_goalkeeping_stats = []\n",
    "    \n",
    "    # Getting squads stats data\n",
    "    get_squad_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/squad_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        df[\"Season\"] = season\n",
    "        seasons_squads_stats.append(df)\n",
    "        \n",
    "    # Getting squad wages data\n",
    "    get_squad_wages()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/squad_wages_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        df[\"Season\"] = season\n",
    "        seasons_squads_wages.append(df)\n",
    "    \n",
    "    # Getting standard player stats\n",
    "    get_standard_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/standard_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        df[\"Season\"] = season\n",
    "        seasons_standard_stats.append(df)\n",
    "        \n",
    "    # Getting defensive player stats\n",
    "    get_defensive_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/defensive_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        df[\"Season\"] = season\n",
    "        seasons_defensive_stats.append(df)\n",
    "    \n",
    "    # Getting passing player stats\n",
    "    get_passing_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/passing_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        df[\"Season\"] = season\n",
    "        seasons_passing_stats.append(df)\n",
    "        \n",
    "    # Getting goalkeeping player stats\n",
    "    get_goalkeeping_stats()\n",
    "    for season in seasons:\n",
    "        file_path = f'data_html/goalkeeping_stats_{season}.txt'\n",
    "        df = get_data_from_txt(file_path)\n",
    "        df[\"Season\"] = season\n",
    "        seasons_goalkeeping_stats.append(df)\n",
    "    \n",
    "    \n",
    "    squads_stats = pd.concat(seasons_squads_stats, ignore_index=True)\n",
    "    squads_wages = pd.concat(seasons_squads_wages, ignore_index=True)\n",
    "    standard_stats = pd.concat(seasons_standard_stats, ignore_index=True)\n",
    "    defensive_stats = pd.concat(seasons_defensive_stats, ignore_index=True)\n",
    "    passing_stats = pd.concat(seasons_passing_stats, ignore_index=True)\n",
    "    goalkeeping_stats = pd.concat(seasons_goalkeeping_stats, ignore_index=True)\n",
    "    \n",
    "    return squads_stats, squads_wages, standard_stats, defensive_stats, passing_stats, goalkeeping_stats\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "834c7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_data():\n",
    "    # get squads stats, squad wages, standard player stats, defensive stats, passing stats, and goalkeeping for all seasons\n",
    "    squads_stats, squads_wages, standard_stats, defensive_stats, passing_stats, goalkeeping_stats = get_all_seasons()\n",
    "\n",
    "    # output paths\n",
    "    stats_output_path = 'uncleaned_data_csv\\seasons_stats.csv'\n",
    "    wages_output_path = 'uncleaned_data_csv\\seasons_wages.csv'\n",
    "    standard_output_path = 'uncleaned_data_csv\\standard.csv'\n",
    "    defending_output_path = 'uncleaned_data_csv\\defending.csv'\n",
    "    passing_output_path = 'uncleaned_data_csv\\passing.csv'\n",
    "    \n",
    "    # To csv\n",
    "    squads_stats.to_csv(stats_output_path, index=False)\n",
    "    squads_wages.to_csv(wages_output_path, index=False)\n",
    "    standard_stats.to_csv(standard_output_path, index=False)\n",
    "    defensive_stats.to_csv(defending_output_path, index=False)\n",
    "    passing_stats.to_csv(passing_output_path, index=False)\n",
    "    \n",
    "    # print them out\n",
    "    print(squads_stats.head())\n",
    "    print(squads_wages.head())\n",
    "    print(standard_stats.head())\n",
    "    print(defensive_stats.head())\n",
    "    print(passing_stats.head())\n",
    "    print(goalkeeping_stats.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b68f20d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for season 2017-2018: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2017-2018/stats/squads/2017-2018-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2018-2019: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2018-2019/stats/squads/2018-2019-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2019-2020: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2019-2020/stats/squads/2019-2020-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2020-2021: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2020-2021/stats/squads/2020-2021-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2021-2022: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2021-2022/stats/squads/2021-2022-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2022-2023: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2022-2023/stats/squads/2022-2023-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2023-2024: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2023-2024/stats/squads/2023-2024-Big-5-European-Leagues-Stats\n",
      "All seasons processed\n",
      "Failed to fetch data for season 2017-2018: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2017-2018/wages/2017-2018-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2018-2019: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2018-2019/wages/2018-2019-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2019-2020: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2019-2020/wages/2019-2020-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2020-2021: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2020-2021/wages/2020-2021-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2021-2022: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2021-2022/wages/2021-2022-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2022-2023: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2022-2023/wages/2022-2023-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2023-2024: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2023-2024/wages/2023-2024-Big-5-European-Leagues-Stats\n",
      "All seasons processed\n",
      "Failed to fetch data for season 2017-2018: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2017-2018/stats/players/2017-2018-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2018-2019: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2018-2019/stats/players/2018-2019-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2019-2020: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2019-2020/stats/players/2019-2020-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2020-2021: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2020-2021/stats/players/2020-2021-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2021-2022: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2021-2022/stats/players/2021-2022-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2022-2023: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2022-2023/stats/players/2022-2023-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2023-2024: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2023-2024/stats/players/2023-2024-Big-5-European-Leagues-Stats\n",
      "All seasons processed\n",
      "Failed to fetch data for season 2017-2018: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2017-2018/defense/players/2017-2018-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2018-2019: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2018-2019/defense/players/2018-2019-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2019-2020: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2019-2020/defense/players/2019-2020-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2020-2021: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2020-2021/defense/players/2020-2021-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2021-2022: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2021-2022/defense/players/2021-2022-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2022-2023: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2022-2023/defense/players/2022-2023-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2023-2024: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2023-2024/defense/players/2023-2024-Big-5-European-Leagues-Stats\n",
      "All seasons processed\n",
      "Failed to fetch data for season 2017-2018: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2017-2018/passing/players/2017-2018-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2018-2019: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2018-2019/passing/players/2018-2019-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2019-2020: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2019-2020/passing/players/2019-2020-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2020-2021: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2020-2021/passing/players/2020-2021-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2021-2022: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2021-2022/passing/players/2021-2022-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2022-2023: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2022-2023/passing/players/2022-2023-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2023-2024: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2023-2024/passing/players/2023-2024-Big-5-European-Leagues-Stats\n",
      "All seasons processed\n",
      "Failed to fetch data for season 2017-2018: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2017-2018/keepers/players/2017-2018-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2018-2019: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2018-2019/keepers/players/2018-2019-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2019-2020: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2019-2020/keepers/players/2019-2020-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2020-2021: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2020-2021/keepers/players/2020-2021-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2021-2022: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2021-2022/keepers/players/2021-2022-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2022-2023: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2022-2023/keepers/players/2022-2023-Big-5-European-Leagues-Stats\n",
      "Failed to fetch data for season 2023-2024: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/2023-2024/keepers/players/2023-2024-Big-5-European-Leagues-Stats\n",
      "All seasons processed\n",
      "                                                    Rk Squad Competition  \\\n",
      "0  1    Alavés          es La Liga  30  25.5  40.3  38   418       3,420   \n",
      "1  2    Amiens          fr Ligue 1  30  27.5  43.3  38   418       3,420   \n",
      "2  3    Angers          fr Ligue 1  27  27.1  45.1  38   418       3,420   \n",
      "3  4   Arsenal  eng Premier League  30  26.8  61.4  38   418       3,420   \n",
      "4  5  Atalanta          it Serie A  25  25.7  55.4  38   418       3,420   \n",
      "\n",
      "  # of Players  ... npxG: Non-Penalty xG xAG: Exp. Assisted Goals npxG + xAG  \\\n",
      "0         38.0  ...                 0.82                     1.87       1.03   \n",
      "1         38.0  ...                 0.63                     1.58       0.87   \n",
      "2         38.0  ...                 0.79                     1.87       0.97   \n",
      "3         38.0  ...                 1.61                     3.53       1.82   \n",
      "4         38.0  ...                 1.00                     2.50       1.37   \n",
      "\n",
      "  Progressive Carries Progressive Passes Goals/90 Assists/90  \\\n",
      "0                1.84               1.01     0.73       1.74   \n",
      "1                1.50               0.86     0.56       1.42   \n",
      "2                1.76               1.25     0.93       2.18   \n",
      "3                3.42               1.80     1.40       3.20   \n",
      "4                2.37               1.69     1.18       2.86   \n",
      "\n",
      "  Goals + Assists/90 Non-Penalty Goals/90     Season  \n",
      "0               0.95                 1.68  2017-2018  \n",
      "1               0.78                 1.35  2017-2018  \n",
      "2               1.17                 2.10  2017-2018  \n",
      "3               1.69                 3.10  2017-2018  \n",
      "4               1.50                 2.68  2017-2018  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "  Rk           Squad         Competition # of Players  \\\n",
      "0  1       Barcelona          es La Liga           33   \n",
      "1  2     Real Madrid          es La Liga           33   \n",
      "2  3       Paris S-G          fr Ligue 1           35   \n",
      "3  4  Manchester Utd  eng Premier League           35   \n",
      "4  5         Arsenal  eng Premier League           45   \n",
      "\n",
      "                            Weekly Wages  \\\n",
      "0  € 4,682,115 (£ 3,925,993, $4,771,599)   \n",
      "1  € 3,949,904 (£ 3,312,027, $4,025,393)   \n",
      "2  € 3,895,462 (£ 3,266,377, $3,969,910)   \n",
      "3  € 3,810,955 (£ 3,195,596, $3,883,356)   \n",
      "4  € 3,629,433 (£ 3,043,385, $3,698,385)   \n",
      "\n",
      "                                  Annual Wages % Estimated     Season  \n",
      "0  € 243,470,000 (£ 204,151,634, $248,123,125)        100%  2017-2018  \n",
      "1  € 205,395,000 (£ 172,225,426, $209,320,446)        100%  2017-2018  \n",
      "2  € 202,564,000 (£ 169,851,608, $206,435,344)        100%  2017-2018  \n",
      "3  € 198,169,670 (£ 166,171,000, $201,934,520)        100%  2017-2018  \n",
      "4  € 188,730,521 (£ 158,256,000, $192,316,043)        100%  2017-2018  \n",
      "                                                                               \\\n",
      "0  1  Patrick van Aanholt   nl NED     DF  Crystal Palace  eng Premier League   \n",
      "1  2       Rolando Aarons  eng ENG  MF,FW   Newcastle Utd  eng Premier League   \n",
      "2  3       Rolando Aarons  eng ENG  MF,FW   Hellas Verona          it Serie A   \n",
      "3  4        Ignazio Abate   it ITA     DF           Milan          it Serie A   \n",
      "4  5      Aymen Abdennour   tn TUN     DF       Marseille          fr Ligue 1   \n",
      "\n",
      "         Rk Player Nation  ... xAG: Exp. Assisted Goals npxG + xAG  \\\n",
      "0  26  1990     28     25  ...                     0.25       0.21   \n",
      "1  21  1995      4      1  ...                     0.00       0.00   \n",
      "2  21  1995     11      6  ...                     0.00       0.00   \n",
      "3  30  1986     17     11  ...                     0.09       0.09   \n",
      "4  27  1989      8      6  ...                     0.00       0.00   \n",
      "\n",
      "  Progressive Carries Progressive Passes Progressive Passes Rec Goals/90  \\\n",
      "0                0.25               0.13                   0.09     0.21   \n",
      "1                0.00               0.04                   0.00     0.04   \n",
      "2                0.00               0.03                   0.03     0.06   \n",
      "3                0.09               0.01                   0.04     0.06   \n",
      "4                0.00               0.02                   0.00     0.02   \n",
      "\n",
      "  Assists/90 Goals + Assists/90 Non-Penalty Goals/90     Season  \n",
      "0       0.13               0.21              Matches  2017-2018  \n",
      "1       0.04               0.04              Matches  2017-2018  \n",
      "2       0.03               0.06              Matches  2017-2018  \n",
      "3       0.01               0.06              Matches  2017-2018  \n",
      "4       0.02               0.02              Matches  2017-2018  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "                                                                               \\\n",
      "0  1  Patrick van Aanholt   nl NED     DF  Crystal Palace  eng Premier League   \n",
      "1  2       Rolando Aarons  eng ENG  MF,FW   Newcastle Utd  eng Premier League   \n",
      "2  3       Rolando Aarons  eng ENG  MF,FW   Hellas Verona          it Serie A   \n",
      "3  4        Ignazio Abate   it ITA     DF           Milan          it Serie A   \n",
      "4  5      Aymen Abdennour   tn TUN     DF       Marseille          fr Ligue 1   \n",
      "\n",
      "   Rk Player Nation Position  ... Tackles (Def 3rd) Tackles (Mid 3rd)  \\\n",
      "0  26   1990   24.3       47  ...                18                24   \n",
      "1  21   1995    1.5        4  ...                 2                 3   \n",
      "2  21   1995    5.7       13  ...                 6                 3   \n",
      "3  30   1986   11.7       20  ...                 5                22   \n",
      "4  27   1989    5.5        7  ...                 3                 5   \n",
      "\n",
      "  Tackles (Att 3rd) Dribblers Tackled Dribbles Challenged  \\\n",
      "0                 5                19                  47   \n",
      "1                 0                 3                   1   \n",
      "2                 1                 2                   2   \n",
      "3                 2                20                   8   \n",
      "4                 5                 0                   4   \n",
      "\n",
      "  % of Dribblers Tackled Challenges Lost Blocks Shots Blocked     Season  \n",
      "0                     94              64      2       Matches  2017-2018  \n",
      "1                      5               0      0       Matches  2017-2018  \n",
      "2                     15               0      0       Matches  2017-2018  \n",
      "3                     28              29      0       Matches  2017-2018  \n",
      "4                     11              20      0       Matches  2017-2018  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "                                                                               \\\n",
      "0  1  Patrick van Aanholt   nl NED     DF  Crystal Palace  eng Premier League   \n",
      "1  2       Rolando Aarons  eng ENG  MF,FW   Newcastle Utd  eng Premier League   \n",
      "2  3       Rolando Aarons  eng ENG  MF,FW   Hellas Verona          it Serie A   \n",
      "3  4        Ignazio Abate   it ITA     DF           Milan          it Serie A   \n",
      "4  5      Aymen Abdennour   tn TUN     DF       Marseille          fr Ligue 1   \n",
      "\n",
      "                    Rk  ... Passes Attempted (Short)  \\\n",
      "0  26  1990  24.3  884  ...                      2.1   \n",
      "1  21  1995   1.5   29  ...                      0.0   \n",
      "2  21  1995   5.7   87  ...                      0.2   \n",
      "3  30  1986  11.7  625  ...                      0.5   \n",
      "4  27  1989   5.5  310  ...                      0.0   \n",
      "\n",
      "  Pass Completion % (Short) Passes Completed (Medium)  \\\n",
      "0                       1.8                      -1.1   \n",
      "1                       0.0                       0.0   \n",
      "2                       0.1                      -0.2   \n",
      "3                       0.8                      -0.5   \n",
      "4                       0.0                       0.0   \n",
      "\n",
      "  Passes Attempted (Medium) Pass Completion % (Medium)  \\\n",
      "0                        18                         63   \n",
      "1                         0                          2   \n",
      "2                         3                          8   \n",
      "3                        10                         55   \n",
      "4                         0                          8   \n",
      "\n",
      "  Passes Completed (Long) Passes Attempted (Long) Pass Completion % (Long)  \\\n",
      "0                      28                       6                       92   \n",
      "1                       1                       1                        3   \n",
      "2                       7                       1                       17   \n",
      "3                      20                       7                       81   \n",
      "4                       0                       0                       12   \n",
      "\n",
      "   Assists     Season  \n",
      "0  Matches  2017-2018  \n",
      "1  Matches  2017-2018  \n",
      "2  Matches  2017-2018  \n",
      "3  Matches  2017-2018  \n",
      "4  Matches  2017-2018  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "                                                                  Rk Player  \\\n",
      "0  1    Antonio Adán  es ESP  GK       Betis          es La Liga  30   1987   \n",
      "1  2      René Adler  de GER  GK    Mainz 05       de Bundesliga  32   1985   \n",
      "2  3          Adrián  es ESP  GK    West Ham  eng Premier League  30   1987   \n",
      "3  4         Alisson  br BRA  GK        Roma          it Serie A  24   1992   \n",
      "4  5  Sergio Álvarez  es ESP  GK  Celta Vigo          es La Liga  30   1986   \n",
      "\n",
      "  Nation Position  ... Goals Against/90 Shots on Target Against Saves  \\\n",
      "0     30       30  ...               12                       9  30.0   \n",
      "1     14       14  ...                6                       4  28.6   \n",
      "2     19       19  ...                6                       6  31.6   \n",
      "3     37       37  ...                7                      17  45.9   \n",
      "4     17       16  ...                7                       3  18.8   \n",
      "\n",
      "  Save Percentage Wins Draws Losses Clean Sheets Clean Sheet Percentage  \\\n",
      "0               4    3     1      0         25.0                Matches   \n",
      "1               2    1     0      1          0.0                Matches   \n",
      "2               1    1     0      0          0.0                Matches   \n",
      "3               5    3     2      0         40.0                Matches   \n",
      "4               1    1     0      0          0.0                Matches   \n",
      "\n",
      "      Season  \n",
      "0  2017-2018  \n",
      "1  2017-2018  \n",
      "2  2017-2018  \n",
      "3  2017-2018  \n",
      "4  2017-2018  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "scrape_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c54b5d",
   "metadata": {},
   "source": [
    "#Sanity Check#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045b26d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season\n",
      "2021-2022    3036\n",
      "2022-2023    3004\n",
      "2023-2024    2966\n",
      "2020-2021    2934\n",
      "2019-2020    2841\n",
      "2017-2018    2799\n",
      "2018-2019    2762\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('uncleaned_data_csv/defending.csv')\n",
    "print(df['Season'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22120bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Season\n",
       "2017-2018    2799\n",
       "2018-2019    2762\n",
       "2019-2020    2841\n",
       "2020-2021    2934\n",
       "2021-2022    3036\n",
       "2022-2023    3004\n",
       "2023-2024    2966\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('uncleaned_data_csv/passing.csv')\n",
    "df.groupby('Season').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93593f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Progressive Passing Distance    0.057025\n",
       "Passes Attempted                0.022417\n",
       "Year of birth                   0.015289\n",
       "Nation                          0.006243\n",
       "Unnamed: 2                      0.000442\n",
       "90s Played                      0.000295\n",
       "Age                             0.000295\n",
       "Pass Completion % (Short)       0.000295\n",
       "Passes Attempted (Short)        0.000295\n",
       "Pass Completion % (Medium)      0.000295\n",
       "Total Passing Distance          0.000295\n",
       "Pass Completion %               0.000295\n",
       "Passes Completed                0.000295\n",
       "Passes Completed (Long)         0.000295\n",
       "Squad                           0.000295\n",
       "Competition                     0.000295\n",
       "Passes Attempted (Medium)       0.000295\n",
       "Position                        0.000295\n",
       "Player                          0.000295\n",
       "Rk                              0.000295\n",
       "Passes Attempted (Long)         0.000295\n",
       "Pass Completion % (Long)        0.000295\n",
       "Passes Completed (Medium)       0.000295\n",
       "Unnamed: 7                      0.000246\n",
       "Unnamed: 6                      0.000246\n",
       "Unnamed: 3                      0.000049\n",
       "Assists                         0.000000\n",
       "Unnamed: 0                      0.000000\n",
       "Passes Completed (Short)        0.000000\n",
       "Unnamed: 1                      0.000000\n",
       "Unnamed: 8                      0.000000\n",
       "Unnamed: 5                      0.000000\n",
       "Unnamed: 4                      0.000000\n",
       "Season                          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc2427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
